# DDA AI 答題系統 - 端到端測試指導

## 📋 測試目標

驗證 DDA (動態難度調節) 和擬人化延遲機制在完整 WebSocket 流程中的正確性。

---

## 🛠️ 前置準備

### 1. 啟動服務

```bash
# 終端 1: 啟動 Rust WebSocket 服務器
cd services/battle-ws
cargo run

# 預期輸出：
# [INFO] Battle WebSocket server starting on ws://0.0.0.0:8080/ws/battle
```

```bash
# 終端 2: 啟動前端開發服務器
cd apps/web
pnpm dev

# 預期輸出：
# ✓ Ready on http://localhost:3000
```

### 2. 配置環境變數

確認 `apps/web/.env.local` 包含：
```env
NEXT_PUBLIC_WS_URL=ws://localhost:8080/ws/battle
```

### 3. 準備測試工具

- **瀏覽器開發者工具**：開啟 Console 和 Network 標籤
- **日誌監控**：觀察 Rust 服務器終端的日誌輸出
- **測試記錄表**：準備記錄以下數據
  - 每題的答題順序（玩家先或 AI 先）
  - AI 反應時間（從 `OpponentThinking` 到 `OpponentAnswered`）
  - AI 答對/答錯情況
  - 玩家答對/答錯情況

---

## 🧪 測試場景

### 場景 1: DDA 激勵測試（玩家連輸 4 題）

**目標**：驗證玩家連輸後，AI 難度降低（命中率下降、反應變慢）。

#### 測試步驟

1. **啟動對戰**
   - 訪問 `http://localhost:3000/play`
   - 選擇 **PVE_TRAINING** 模式
   - 開始匹配

2. **故意連輸 4 題**
   - 第 1-4 題：**故意選擇錯誤答案**
   - 記錄每題的結果：
     - AI 是否答對
     - AI 反應時間（從 `OpponentThinking` 到 `OpponentAnswered` 的時間差）

3. **觀察第 5-8 題**
   - 繼續故意答錯（維持連輸狀態）
   - 記錄：
     - AI 命中率（答對題數 / 總題數）
     - 平均反應時間

#### 驗證標準

| 指標 | 預期結果 | 記錄值 |
|------|---------|--------|
| **AI 命中率** | ≤ 70% | ___% |
| **平均反應時間** | ≥ 2000ms | ___ms |
| **UserFactor** | ≈ +0.15（從日誌觀察） | ___ |

#### 日誌檢查點

在 Rust 服務器終端查找：
```
AI plan: q=4, correct=true/false, p=0.XX, m_ai=0.XX, user_factor=0.XX, rt=XXXXms
```

**預期**：
- `user_factor` 應 < 0.8（連輸後降低）
- `p`（答對概率）應 < 0.7
- `rt`（反應時間）應 ≥ 2000ms

---

### 場景 2: DDA 挑戰測試（玩家連勝 4 題）

**目標**：驗證玩家連勝後，AI 難度提高（命中率上升、反應變快），但仍有 15%+ 失誤。

#### 測試步驟

1. **啟動新對戰**
   - 重新開始一局 PVE_TRAINING

2. **故意連勝 4 題**
   - 第 1-4 題：**選擇正確答案**
   - 記錄每題的結果

3. **觀察第 5-8 題**
   - 繼續答對（維持連勝狀態）
   - 記錄：
     - AI 命中率
     - 平均反應時間
     - AI 失誤次數（應 ≥ 1 次，因為下限 15%）

#### 驗證標準

| 指標 | 預期結果 | 記錄值 |
|------|---------|--------|
| **AI 命中率** | ≥ 75% | ___% |
| **平均反應時間** | ≤ 1200ms | ___ms |
| **AI 失誤次數** | ≥ 1 次（20 題中） | ___次 |
| **UserFactor** | ≈ -0.10（從日誌觀察） | ___ |

#### 日誌檢查點

**預期**：
- `user_factor` 應 > 1.2（連勝後提高）
- `p`（答對概率）應 > 0.75
- `rt`（反應時間）應 ≤ 1200ms

---

### 場景 3: 擬人化競態測試（一般對局）

**目標**：驗證 AI 反應時間的隨機性，導致「AI 早於玩家」和「AI 晚於玩家」兩種情況都會發生。

#### 測試步驟

1. **啟動對戰**
   - 開始一局 PVE_TRAINING

2. **正常答題（不故意輸或贏）**
   - 第 1-10 題：正常答題（混合對錯）
   - 記錄每題的**答題順序**：
     - 玩家先答 → AI 後答
     - AI 先答 → 玩家後答

3. **統計結果**
   - 計算「AI 先答」的次數
   - 計算「玩家先答」的次數

#### 驗證標準

| 指標 | 預期結果 | 記錄值 |
|------|---------|--------|
| **AI 先答次數** | ≥ 2 次（10 題中） | ___次 |
| **玩家先答次數** | ≥ 2 次（10 題中） | ___次 |
| **反應時間範圍** | 800-4000ms | ___ms |

#### 觀察要點

- **AI 先答**：`OpponentAnswered` 消息在玩家 `SubmitAnswer` 之前到達
- **玩家先答**：玩家 `SubmitAnswer` 在 `OpponentAnswered` 之前發送

**預期**：兩種情況都應該發生，因為反應時間是隨機的（800-4000ms）。

---

### 場景 4: 異步任務取消測試（玩家答題極快）

**目標**：驗證當玩家極快答題時，AI 的延遲任務能被正確取消，不會發送重複的 `OpponentAnswered` 消息。

#### 測試步驟

1. **啟動對戰**
   - 開始一局 PVE_TRAINING

2. **極快答題**
   - 第 1-5 題：**在 0.5 秒內快速提交答案**
   - 觀察：
     - 是否收到 `OpponentThinking` 消息
     - 是否收到 `OpponentAnswered` 消息（**預期：不應收到**）
     - 是否收到 `RoundResolved` 消息（**預期：應收到**）

3. **檢查日誌**
   - 在 Rust 服務器終端查找：
     - `Aborting AI answer task`（任務取消日誌）
     - `AI answer task aborted`（確認取消）

#### 驗證標準

| 指標 | 預期結果 | 實際結果 |
|------|---------|---------|
| **收到 OpponentThinking** | ✅ 是 | ___ |
| **收到 OpponentAnswered** | ❌ 否（任務應被取消） | ___ |
| **收到 RoundResolved** | ✅ 是 | ___ |
| **日誌顯示任務取消** | ✅ 是 | ___ |
| **無重複結算** | ✅ 是（只結算一次） | ___ |

#### 關鍵檢查點

1. **消息順序**：
   ```
   RoundStarted → OpponentThinking → SubmitAnswer (玩家極快) → RoundResolved
   ```
   **不應出現**：`OpponentAnswered`（因為任務被取消）

2. **日誌確認**：
   ```
   [INFO] Aborting AI answer task for match=xxx, question=0
   [INFO] AI answer task aborted
   ```

---

## 📊 測試記錄表模板

### 場景 1: DDA 激勵測試

| 題號 | 玩家答案 | AI 答案 | AI 答對 | AI 反應時間 (ms) | 備註 |
|------|---------|---------|---------|-----------------|------|
| 1 | ❌ | ___ | ___ | ___ | 故意答錯 |
| 2 | ❌ | ___ | ___ | ___ | 故意答錯 |
| 3 | ❌ | ___ | ___ | ___ | 故意答錯 |
| 4 | ❌ | ___ | ___ | ___ | 故意答錯 |
| 5 | ❌ | ___ | ___ | ___ | 觀察 AI 變化 |
| 6 | ❌ | ___ | ___ | ___ | 觀察 AI 變化 |
| 7 | ❌ | ___ | ___ | ___ | 觀察 AI 變化 |
| 8 | ❌ | ___ | ___ | ___ | 觀察 AI 變化 |

**統計結果**：
- AI 命中率（第 5-8 題）：___%
- 平均反應時間（第 5-8 題）：___ms
- UserFactor（從日誌）：___

---

### 場景 2: DDA 挑戰測試

| 題號 | 玩家答案 | AI 答案 | AI 答對 | AI 反應時間 (ms) | 備註 |
|------|---------|---------|---------|-----------------|------|
| 1 | ✅ | ___ | ___ | ___ | 故意答對 |
| 2 | ✅ | ___ | ___ | ___ | 故意答對 |
| 3 | ✅ | ___ | ___ | ___ | 故意答對 |
| 4 | ✅ | ___ | ___ | ___ | 故意答對 |
| 5 | ✅ | ___ | ___ | ___ | 觀察 AI 變化 |
| 6 | ✅ | ___ | ___ | ___ | 觀察 AI 變化 |
| 7 | ✅ | ___ | ___ | ___ | 觀察 AI 變化 |
| 8 | ✅ | ___ | ___ | ___ | 觀察 AI 變化 |

**統計結果**：
- AI 命中率（第 5-8 題）：___%
- 平均反應時間（第 5-8 題）：___ms
- AI 失誤次數（20 題中）：___次
- UserFactor（從日誌）：___

---

### 場景 3: 擬人化競態測試

| 題號 | 答題順序 | AI 反應時間 (ms) | 備註 |
|------|---------|-----------------|------|
| 1 | AI 先 / 玩家先 | ___ | ___ |
| 2 | AI 先 / 玩家先 | ___ | ___ |
| 3 | AI 先 / 玩家先 | ___ | ___ |
| ... | ... | ... | ... |

**統計結果**：
- AI 先答次數：___次
- 玩家先答次數：___次
- 反應時間範圍：___ms - ___ms

---

### 場景 4: 異步任務取消測試

| 題號 | 玩家答題時間 (ms) | 收到 OpponentThinking | 收到 OpponentAnswered | 收到 RoundResolved | 任務取消日誌 |
|------|------------------|---------------------|---------------------|-------------------|------------|
| 1 | < 500 | ✅ / ❌ | ✅ / ❌ | ✅ / ❌ | ✅ / ❌ |
| 2 | < 500 | ✅ / ❌ | ✅ / ❌ | ✅ / ❌ | ✅ / ❌ |
| 3 | < 500 | ✅ / ❌ | ✅ / ❌ | ✅ / ❌ | ✅ / ❌ |

**驗證結果**：
- ✅ 所有任務都被正確取消
- ✅ 無重複結算
- ✅ 消息順序正確

---

## 🔍 故障排除

### 問題 1: WebSocket 連接失敗

**症狀**：前端無法連接到 WebSocket 服務器

**解決方案**：
1. 確認 Rust 服務器正在運行（`cargo run`）
2. 檢查端口 8080 是否被占用：`lsof -i :8080`
3. 確認 `NEXT_PUBLIC_WS_URL` 環境變數正確

### 問題 2: 無法觀察到 DDA 效果

**症狀**：連輸/連勝後，AI 行為沒有明顯變化

**解決方案**：
1. 確認至少連輸/連勝 **4 題**（DDA 窗口默認為 5）
2. 檢查日誌中的 `user_factor` 值是否變化
3. 統計更多題目（建議 20 題）以獲得統計意義

### 問題 3: AI 任務未被取消

**症狀**：玩家極快答題後，仍收到 `OpponentAnswered` 消息

**解決方案**：
1. 檢查日誌中是否有 `Aborting AI answer task` 消息
2. 確認 `submit_ai_answer` 函數中的競態檢查邏輯
3. 驗證 `abort_tx` 是否正確發送

---

## ✅ 測試完成檢查清單

- [ ] 場景 1: DDA 激勵測試通過（AI 命中率 ≤ 70%，反應時間 ≥ 2000ms）
- [ ] 場景 2: DDA 挑戰測試通過（AI 命中率 ≥ 75%，反應時間 ≤ 1200ms，仍有失誤）
- [ ] 場景 3: 擬人化競態測試通過（AI 先答和玩家先答都發生）
- [ ] 場景 4: 異步任務取消測試通過（任務正確取消，無重複結算）
- [ ] 所有日誌檢查點通過
- [ ] 無編譯錯誤或運行時錯誤

---

## 📝 測試報告模板

### 測試日期
**日期**：___年___月___日  
**測試人員**：___

### 測試環境
- Rust 服務器版本：___
- 前端版本：___
- 瀏覽器：___

### 測試結果摘要

| 場景 | 狀態 | 備註 |
|------|------|------|
| 場景 1: DDA 激勵 | ✅ / ❌ | ___ |
| 場景 2: DDA 挑戰 | ✅ / ❌ | ___ |
| 場景 3: 擬人化競態 | ✅ / ❌ | ___ |
| 場景 4: 異步任務取消 | ✅ / ❌ | ___ |

### 發現的問題

1. **問題描述**：___  
   **嚴重程度**：高 / 中 / 低  
   **復現步驟**：___

2. **問題描述**：___  
   **嚴重程度**：高 / 中 / 低  
   **復現步驟**：___

### 建議改進

1. ___
2. ___

---

**測試完成後，請將此報告保存為 `E2E_TEST_REPORT.md`**

